{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open notebooks/paper_td2c/new_descriptors_only_ts_cmiknn_entropy/P10_N10_Nj2_n0.01_MB5.pkl \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "datas = []\n",
    "for file in os.listdir(\".\"):\n",
    "    if file.endswith(\".pkl\"):\n",
    "        with open(file, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "        datas.append(data)\n",
    "\n",
    "new_descriptors = pd.concat(datas)\n",
    "\n",
    "datas = []\n",
    "for file in os.listdir(\"../descriptors_ts_cmiknn_entropy\"):\n",
    "    if file.endswith(\".pkl\"):\n",
    "        if 'N5' in file:\n",
    "            with open('../descriptors_ts_cmiknn_entropy/'+file, \"rb\") as f:\n",
    "                data = pickle.load(f)\n",
    "            datas.append(data)\n",
    "\n",
    "old_descriptors = pd.concat(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_descriptors.max_neighborhood_size  .unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   process_id  graph_id  n_variables  max_neighborhood_size  noise_std  \\\n",
       " 0          13         0            5                      2       0.01   \n",
       " 1          13         0            5                      2       0.01   \n",
       " 2          13         0            5                      2       0.01   \n",
       " 3          13         0            5                      2       0.01   \n",
       " 4          13         0            5                      2       0.01   \n",
       " \n",
       "    edge_source  edge_dest  is_causal  coeff_cause  coeff_eff  ...  \\\n",
       " 0           11          1          1    -0.000155   0.012058  ...   \n",
       " 1           14          4          1    -0.004704  -0.007483  ...   \n",
       " 2           14          1          1     0.104100   0.079396  ...   \n",
       " 3            6          1          1     0.077293   0.075984  ...   \n",
       " 4           12          0          1    -0.010915   0.002934  ...   \n",
       " \n",
       "    mca_mca_cau_q1  mca_mca_cau_q2  mbe_mbe_eff_q0  mbe_mbe_eff_q1  \\\n",
       " 0       -0.031217       -0.031217             0.0             0.0   \n",
       " 1       -0.031217       -0.031217             0.0             0.0   \n",
       " 2       -0.031217       -0.031217             0.0             0.0   \n",
       " 3       -0.020258       -0.020258             0.0             0.0   \n",
       " 4       -0.031217       -0.031217             0.0             0.0   \n",
       " \n",
       "    mbe_mbe_eff_q2  n_samples  n_features  n_features/n_samples  skewness_ca  \\\n",
       " 0             0.0        245          30              0.122449    -0.115084   \n",
       " 1             0.0        245          30              0.122449    -0.048607   \n",
       " 2             0.0        245          30              0.122449    -0.048607   \n",
       " 3             0.0        245          30              0.122449    -0.123903   \n",
       " 4             0.0        245          30              0.122449    -0.030978   \n",
       " \n",
       "    skewness_ef  \n",
       " 0    -0.136400  \n",
       " 1    -0.064535  \n",
       " 2    -0.136400  \n",
       " 3    -0.136400  \n",
       " 4     0.161065  \n",
       " \n",
       " [5 rows x 56 columns],\n",
       " (90000, 56))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_descriptors.head(), old_descriptors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>process_id</th>\n",
       "      <th>graph_id</th>\n",
       "      <th>edge_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4913</th>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4928</th>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4929</th>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4934</th>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4943</th>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      process_id  graph_id  edge_source\n",
       "0             13         0           11\n",
       "1             13         0           14\n",
       "3             13         0            6\n",
       "4             13         0           12\n",
       "5             13         0            7\n",
       "...          ...       ...          ...\n",
       "4913           4        39           21\n",
       "4928           4        39           16\n",
       "4929           4        39           26\n",
       "4934           4        39           20\n",
       "4943           4        39           15\n",
       "\n",
       "[18000 rows x 3 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_descriptors[['process_id','graph_id','edge_source']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>process_id</th>\n",
       "      <th>graph_id</th>\n",
       "      <th>edge_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4913</th>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4928</th>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4929</th>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4934</th>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4943</th>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      process_id  graph_id  edge_source\n",
       "0             13         0           11\n",
       "1             13         0           14\n",
       "3             13         0            6\n",
       "4             13         0           12\n",
       "5             13         0            7\n",
       "...          ...       ...          ...\n",
       "4913           4        39           21\n",
       "4928           4        39           16\n",
       "4929           4        39           26\n",
       "4934           4        39           20\n",
       "4943           4        39           15\n",
       "\n",
       "[19200 rows x 3 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_descriptors[['process_id','graph_id','edge_source']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(new_descriptors, old_descriptors, on=['process_id', 'graph_id', 'edge_source', 'edge_dest','n_variables', 'max_neighborhood_size', 'noise_std', 'is_causal'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['process_id', 'graph_id', 'n_variables', 'max_neighborhood_size',\n",
       "       'noise_std', 'edge_source', 'edge_dest', 'is_causal', 'delta_mi',\n",
       "       'delta_mi_after', 'coeff_cause', 'coeff_eff', 'HOC_3_1', 'HOC_1_2',\n",
       "       'HOC_2_1', 'HOC_1_3', 'kurtosis_ca', 'kurtosis_ef', 'mca_mef_cau_q0',\n",
       "       'mca_mef_cau_q1', 'mca_mef_cau_q2', 'mca_mef_eff_q0', 'mca_mef_eff_q1',\n",
       "       'mca_mef_eff_q2', 'cau_m_eff_q0', 'cau_m_eff_q1', 'cau_m_eff_q2',\n",
       "       'eff_m_cau_q0', 'eff_m_cau_q1', 'eff_m_cau_q2', 'm_cau_q0', 'm_cau_q1',\n",
       "       'm_cau_q2', 'com_cau', 'cau_eff', 'eff_cau', 'eff_cau_mbeff',\n",
       "       'cau_eff_mbcau', 'eff_cau_mbcau_plus_q0', 'eff_cau_mbcau_plus_q1',\n",
       "       'eff_cau_mbcau_plus_q2', 'cau_eff_mbeff_plus_q0',\n",
       "       'cau_eff_mbeff_plus_q1', 'cau_eff_mbeff_plus_q2', 'm_eff_q0',\n",
       "       'm_eff_q1', 'm_eff_q2', 'mca_mca_cau_q0', 'mca_mca_cau_q1',\n",
       "       'mca_mca_cau_q2', 'mbe_mbe_eff_q0', 'mbe_mbe_eff_q1', 'mbe_mbe_eff_q2',\n",
       "       'n_samples', 'n_features', 'n_features/n_samples', 'skewness_ca',\n",
       "       'skewness_ef'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8974603243543087\n",
      "\n",
      "0.6900133851363974\n",
      "\n",
      "0.6416903687277417\n",
      "\n",
      "0.9568535925241849\n",
      "\n",
      "0.6732635945967587\n",
      "\n",
      "0.879157545184386\n",
      "\n",
      "0.739050476351168\n",
      "\n",
      "1.0\n",
      "\n",
      "0.8832158384694218\n",
      "\n",
      "0.9775115916298953\n",
      "\n",
      "1.0\n",
      "\n",
      "0.751882125637632\n",
      "\n",
      "0.9729693820095606\n",
      "\n",
      "1.0\n",
      "\n",
      "0.9109428659516584\n",
      "\n",
      "1.0\n",
      "\n",
      "0.917330399701113\n",
      "\n",
      "0.8912620903568546\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lopo cross validation with group by process_id column classify on 'is_causal' column\n",
    "\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X = merged_df[['coeff_cause', 'coeff_eff', 'HOC_3_1', 'HOC_1_2',\n",
    "       'HOC_2_1', 'HOC_1_3', 'kurtosis_ca', 'kurtosis_ef', 'mca_mef_cau_q0',\n",
    "       'mca_mef_cau_q1', 'mca_mef_cau_q2', 'mca_mef_eff_q0', 'mca_mef_eff_q1',\n",
    "       'mca_mef_eff_q2', 'cau_m_eff_q0', 'cau_m_eff_q1', 'cau_m_eff_q2',\n",
    "       'eff_m_cau_q0', 'eff_m_cau_q1', 'eff_m_cau_q2', 'm_cau_q0', 'm_cau_q1',\n",
    "       'm_cau_q2', 'com_cau', 'cau_eff', 'eff_cau', 'eff_cau_mbeff',\n",
    "       'cau_eff_mbcau', 'eff_cau_mbcau_plus_q0', 'eff_cau_mbcau_plus_q1',\n",
    "       'eff_cau_mbcau_plus_q2', 'cau_eff_mbeff_plus_q0',\n",
    "       'cau_eff_mbeff_plus_q1', 'cau_eff_mbeff_plus_q2', 'm_eff_q0',\n",
    "       'm_eff_q1', 'm_eff_q2', 'mca_mca_cau_q0', 'mca_mca_cau_q1',\n",
    "       'mca_mca_cau_q2', 'mbe_mbe_eff_q0', 'mbe_mbe_eff_q1', 'mbe_mbe_eff_q2',\n",
    "       'n_samples', 'n_features', 'n_features/n_samples', 'skewness_ca',\n",
    "       'skewness_ef']]\n",
    "y = merged_df['is_causal']\n",
    "groups = merged_df['process_id']\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "for train_index, test_index in logo.split(X, y, groups):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    clf = BalancedRandomForestClassifier(n_estimators=40, n_jobs=40, sampling_strategy='not majority', replacement=False, bootstrap=False)\n",
    "    # clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict_proba(X_test)[:,1]\n",
    "    # print(confusion_matrix(y_test, y_pred))\n",
    "    print(roc_auc_score(y_test, y_pred))\n",
    "    # print(classification_report(y_test, y_pred))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydotplus\n",
      "  Downloading pydotplus-2.0.2.tar.gz (278 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.1 in /home/gpaldino/.cache/pypoetry/virtualenvs/td2c-qBinhRvk-py3.10/lib/python3.10/site-packages (from pydotplus) (3.1.4)\n",
      "Building wheels for collected packages: pydotplus\n",
      "  Building wheel for pydotplus (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pydotplus: filename=pydotplus-2.0.2-py3-none-any.whl size=24551 sha256=1b4be4d5a9c5fa0d7f342444b4da8a2db56391f85d2b2380ace63e263321fa1f\n",
      "  Stored in directory: /home/gpaldino/.cache/pip/wheels/69/b2/67/08f0eef649af92df772c09f451558298e07fab1bc7cdf33db0\n",
      "Successfully built pydotplus\n",
      "Installing collected packages: pydotplus\n",
      "Successfully installed pydotplus-2.0.2\n"
     ]
    }
   ],
   "source": [
    "0.9141603651957647\n",
    "\n",
    "0.7257886835714588\n",
    "\n",
    "0.8010488162025683\n",
    "\n",
    "0.9425373668842846\n",
    "\n",
    "0.715950620865117\n",
    "\n",
    "0.9039997038823144\n",
    "\n",
    "0.7749832026707\n",
    "\n",
    "1.0\n",
    "\n",
    "0.8856758797484434\n",
    "\n",
    "0.9785041339170802\n",
    "\n",
    "1.0\n",
    "\n",
    "0.7420158289254353\n",
    "\n",
    "0.9713477029325244\n",
    "\n",
    "1.0\n",
    "\n",
    "0.9059246529393461\n",
    "\n",
    "1.0\n",
    "\n",
    "0.9350675885362371\n",
    "\n",
    "0.90096729859679\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print decision tree\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "\n",
    "dot_data = export_graphviz(clf, out_file=None,\n",
    "                            feature_names=X.columns,\n",
    "                            class_names=['False', 'True'],\n",
    "                            filled=True, rounded=True,\n",
    "                            special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "graph.write_png(\"decision_tree.png\")\n",
    "\n",
    "# print feature importance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "td2c-qBinhRvk-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
