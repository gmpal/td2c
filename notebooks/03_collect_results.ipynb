{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare\n",
    "\n",
    "In this notebook, we compare the performance of different causal inference methods using various metrics. We load multiple datasets generated by different methods and evaluate how well each method identifies causal relationships compared to the ground truth.\n",
    "\n",
    "We employ metrics such as accuracy, balanced accuracy, precision, recall, and F1-score to assess the performance of each method. Additionally, we aggregate the results into a comprehensive table for easy comparison and analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('example/causal_dfs.pkl', 'rb') as f:\n",
    "    causal_dfs_var, causal_dfs_varlingam, causal_dfs_pcmci, causal_dfs_granger, causal_dfs_dynotears, causal_dfs_d2c, true_causal_dfs = pickle.load(f)\n",
    "    \n",
    "causal_dfs_varlingam = pd.concat(causal_dfs_varlingam.values()).reset_index(drop=True)\n",
    "causal_dfs_var = pd.concat(causal_dfs_var.values()).reset_index(drop=True)\n",
    "causal_dfs_pcmci = pd.concat(causal_dfs_pcmci.values()).reset_index(drop=True)\n",
    "causal_dfs_granger = pd.concat(causal_dfs_granger.values()).reset_index(drop=True)\n",
    "causal_dfs_dynotears = pd.concat(causal_dfs_dynotears.values()).reset_index(drop=True)\n",
    "causal_dfs_d2c = pd.concat(causal_dfs_d2c.values()).reset_index(drop=True)\n",
    "true_causal_dfs = pd.concat(true_causal_dfs.values()).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We perform a sanity check to ensure that the causal_dfs are the same across all methods\n",
    "\n",
    "assert (causal_dfs_varlingam['from'] == causal_dfs_var['from']).all()\n",
    "assert (causal_dfs_varlingam['from'] == causal_dfs_pcmci['from']).all()\n",
    "assert (causal_dfs_varlingam['from'] == causal_dfs_granger['from']).all()\n",
    "assert (causal_dfs_varlingam['from'] == causal_dfs_dynotears['from']).all()\n",
    "assert (causal_dfs_varlingam['from'] == causal_dfs_d2c['from']).all()\n",
    "assert (causal_dfs_varlingam['from'] == true_causal_dfs['from']).all()\n",
    "\n",
    "assert (causal_dfs_varlingam['to'] == causal_dfs_var['to']).all()\n",
    "assert (causal_dfs_varlingam['to'] == causal_dfs_pcmci['to']).all()\n",
    "assert (causal_dfs_varlingam['to'] == causal_dfs_granger['to']).all()\n",
    "assert (causal_dfs_varlingam['to'] == causal_dfs_dynotears['to']).all()\n",
    "assert (causal_dfs_varlingam['to'] == causal_dfs_d2c['to']).all()\n",
    "assert (causal_dfs_varlingam['to'] == true_causal_dfs['to']).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = true_causal_dfs['is_causal'].astype(int)\n",
    "y_pred_var = causal_dfs_var['is_causal'].astype(int)\n",
    "y_pred_pcmci = causal_dfs_pcmci['is_causal'].astype(int)\n",
    "y_pred_granger = causal_dfs_granger['is_causal'].astype(int)\n",
    "y_pred_dynotears = causal_dfs_dynotears['is_causal'].astype(int)\n",
    "y_pred_d2c = causal_dfs_d2c['is_causal'].astype(int)\n",
    "y_pred_varlingam = causal_dfs_varlingam['is_causal'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_predictions = pd.concat([y_pred_var, \n",
    "                                y_pred_varlingam,\n",
    "                                y_pred_pcmci, \n",
    "                                y_pred_granger, \n",
    "                                y_pred_dynotears,\n",
    "                                y_pred_d2c, \n",
    "                                y_true], axis=1)\n",
    "concat_predictions.columns = ['VAR', 'VarLingam', 'PCMCI', 'Granger', 'Dynotears', 'D2C', 'True']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"Method\",\n",
    "        \"Accuracy\",\n",
    "        \"Balanced Accuracy\",\n",
    "        \"Precision\",\n",
    "        \"Recall\",\n",
    "        \"F1\",\n",
    "        \"Total\",\n",
    "        \"Positive\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "scores.loc[len(scores)] = [\n",
    "    \"VAR\",\n",
    "    accuracy_score(y_true, y_pred_var),\n",
    "    balanced_accuracy_score(y_true, y_pred_var),\n",
    "    precision_score(y_true, y_pred_var, zero_division=np.nan),\n",
    "    recall_score(y_true, y_pred_var, zero_division=np.nan),\n",
    "    f1_score(y_true, y_pred_var, zero_division=np.nan),\n",
    "    len(y_true),\n",
    "    y_true.sum(),\n",
    "]\n",
    "\n",
    "scores.loc[len(scores)] = [\n",
    "    \"PCMCI\",\n",
    "    accuracy_score(y_true, y_pred_pcmci),\n",
    "    balanced_accuracy_score(y_true, y_pred_pcmci),\n",
    "    precision_score(y_true, y_pred_pcmci, zero_division=np.nan),\n",
    "    recall_score(y_true, y_pred_pcmci, zero_division=np.nan),\n",
    "    f1_score(y_true, y_pred_pcmci, zero_division=np.nan),\n",
    "    len(y_true),\n",
    "    y_true.sum(),\n",
    "]\n",
    "\n",
    "scores.loc[len(scores)] = [\n",
    "    \"Granger\",\n",
    "    accuracy_score(y_true, y_pred_granger),\n",
    "    balanced_accuracy_score(y_true, y_pred_granger),\n",
    "    precision_score(y_true, y_pred_granger, zero_division=np.nan),\n",
    "    recall_score(y_true, y_pred_granger, zero_division=np.nan),\n",
    "    f1_score(y_true, y_pred_granger, zero_division=np.nan),\n",
    "    len(y_true),\n",
    "    y_true.sum(),\n",
    "]\n",
    "\n",
    "scores.loc[len(scores)] = [\n",
    "    \"Dynotears\",\n",
    "    accuracy_score(y_true, y_pred_dynotears),\n",
    "    balanced_accuracy_score(y_true, y_pred_dynotears),\n",
    "    precision_score(y_true, y_pred_dynotears, zero_division=np.nan),\n",
    "    recall_score(y_true, y_pred_dynotears, zero_division=np.nan),\n",
    "    f1_score(y_true, y_pred_dynotears, zero_division=np.nan),\n",
    "    len(y_true),\n",
    "    y_true.sum(),\n",
    "]\n",
    "\n",
    "scores.loc[len(scores)] = [\n",
    "    \"VarLingam\",\n",
    "    accuracy_score(y_true, y_pred_varlingam),\n",
    "    balanced_accuracy_score(y_true, y_pred_varlingam),\n",
    "    precision_score(y_true, y_pred_varlingam, zero_division=np.nan),\n",
    "    recall_score(y_true, y_pred_varlingam, zero_division=np.nan),\n",
    "    f1_score(y_true, y_pred_varlingam, zero_division=np.nan),\n",
    "    len(y_true),\n",
    "    y_true.sum(),\n",
    "]\n",
    "\n",
    "scores.loc[len(scores)] = [\n",
    "    \"D2C\",\n",
    "    accuracy_score(y_true, y_pred_d2c),\n",
    "    balanced_accuracy_score(y_true, y_pred_d2c),\n",
    "    precision_score(y_true, y_pred_d2c, zero_division=np.nan),\n",
    "    recall_score(y_true, y_pred_d2c, zero_division=np.nan),\n",
    "    f1_score(y_true, y_pred_d2c, zero_division=np.nan),\n",
    "    len(y_true),\n",
    "    y_true.sum(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Total</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VAR</td>\n",
       "      <td>0.9334</td>\n",
       "      <td>0.585005</td>\n",
       "      <td>0.393103</td>\n",
       "      <td>0.188742</td>\n",
       "      <td>0.255034</td>\n",
       "      <td>5000</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PCMCI</td>\n",
       "      <td>0.9586</td>\n",
       "      <td>0.977969</td>\n",
       "      <td>0.593320</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.744760</td>\n",
       "      <td>5000</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Granger</td>\n",
       "      <td>0.7316</td>\n",
       "      <td>0.437340</td>\n",
       "      <td>0.028131</td>\n",
       "      <td>0.102649</td>\n",
       "      <td>0.044160</td>\n",
       "      <td>5000</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dynotears</td>\n",
       "      <td>0.9396</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5000</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VarLingam</td>\n",
       "      <td>0.9546</td>\n",
       "      <td>0.975841</td>\n",
       "      <td>0.570888</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.726835</td>\n",
       "      <td>5000</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>D2C</td>\n",
       "      <td>0.6594</td>\n",
       "      <td>0.494970</td>\n",
       "      <td>0.058601</td>\n",
       "      <td>0.307947</td>\n",
       "      <td>0.098465</td>\n",
       "      <td>5000</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Method  Accuracy  Balanced Accuracy  ...        F1  Total  Positive\n",
       "0        VAR    0.9334           0.585005  ...  0.255034   5000       302\n",
       "1      PCMCI    0.9586           0.977969  ...  0.744760   5000       302\n",
       "2    Granger    0.7316           0.437340  ...  0.044160   5000       302\n",
       "3  Dynotears    0.9396           0.500000  ...  0.000000   5000       302\n",
       "4  VarLingam    0.9546           0.975841  ...  0.726835   5000       302\n",
       "5        D2C    0.6594           0.494970  ...  0.098465   5000       302\n",
       "\n",
       "[6 rows x 8 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "The results presented in this notebook indicate varying performances of different causal inference methods when applied to a limited training dataset. It's important to note that these methods typically require larger and more diverse datasets to achieve reliable and accurate results, particularly for complex tasks like causal inference. \n",
    "\n",
    "For more detailed and complete results, please refer to the `submission` branch or further experimentation with broader datasets.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "td2c-qBinhRvk-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
