{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook generates the training descriptors. \n",
    "For each file; only a subset of 300 couples of variables are chosen, according to the following logic\n",
    "\n",
    "- 100 causal couples: A selection of 20 pairs of variables that are causally related according to the DAG. These serve as positive examples.\n",
    "- 100 opposite couples: For each of the causal couples selected, the corresponding opposite pair (effect as cause and cause as effect) is also chosen. These pairs, despite being theoretically informative, do not respect the temporal ordering and thus they won't appear in the results returned by competitor methods. For this reason, they will be excluded from the evaluation phase later on, although they will remain in the training set of our classifier.\n",
    "- 100 additional noncausal couples: To compensate for the exclusion of the opposite couples in validation and ensure a balanced dataset. Unlike the opposite ones, these pairs are chosen based on their lack of causal connection in the DAG and are more likely to resemble noncausal relationships encountered in real-world scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 486/486 [4:09:47<00:00, 30.84s/it]  \n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "import os\n",
    "import pandas as pd\n",
    "from d2c.descriptors import D2C, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "N_JOBS = 40\n",
    "SEED = 42\n",
    "MB_SIZE = 5\n",
    "COUPLES_TO_CONSIDER_PER_DAG = 60\n",
    "maxlags = 5  \n",
    "\n",
    "root = './data/'\n",
    "for file in tqdm(sorted(os.listdir(root))):\n",
    "    gen_process_number = int(file.split('_')[0][1:])\n",
    "    n_variables = int(file.split('_')[1][1:])\n",
    "    max_neighborhood_size = int(file.split('_')[2][2:])\n",
    "    noise_std = float(file.split('_')[3][1:-4])\n",
    "\n",
    "    dataloader = DataLoader(n_variables = n_variables,\n",
    "                    maxlags = maxlags)\n",
    "    dataloader.from_pickle(root+file)\n",
    "\n",
    "    d2c = D2C(observations=dataloader.get_observations(), \n",
    "            dags=dataloader.get_dags(), \n",
    "            couples_to_consider_per_dag=COUPLES_TO_CONSIDER_PER_DAG, \n",
    "            MB_size=MB_SIZE, \n",
    "            n_variables=n_variables, \n",
    "            maxlags=maxlags,\n",
    "            seed=SEED,\n",
    "            n_jobs=N_JOBS,\n",
    "            full=True)\n",
    "\n",
    "    d2c.initialize()\n",
    "\n",
    "    descriptors_df = d2c.get_descriptors_df()\n",
    "\n",
    "    descriptors_df.insert(0, 'process_id', gen_process_number)\n",
    "    descriptors_df.insert(2, 'n_variables', n_variables)\n",
    "    descriptors_df.insert(3, 'max_neighborhood_size', max_neighborhood_size)\n",
    "    descriptors_df.insert(4, 'noise_std', noise_std)\n",
    "\n",
    "    descriptors_df.to_pickle(f'./descriptors/P{gen_process_number}_N{n_variables}_Nj{max_neighborhood_size}_n{noise_std}_MB{MB_SIZE}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2cpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
